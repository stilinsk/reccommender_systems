{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba42c210",
   "metadata": {},
   "source": [
    "## In the following notebook we will be implemementing a movie reccommender system based on a tensorflow movie  dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "677ba18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7da0f6",
   "metadata": {},
   "source": [
    "### typing: This module provides support for type hints in Python.\n",
    "### Dict and Text: These are type hints used for defining the types of variables.\n",
    "### numpy (imported as np): A popular library for numerical operations in Python.\n",
    "### tensorflow (imported as tf): A powerful library for machine learning and deep learning.\n",
    "### tensorflow_datasets (imported as tfds): A library for accessing and preprocessing various datasets in TensorFlow.\n",
    "### tensorflow_recommenders (imported as tfrs): A library built on TensorFlow for building recommendation systems.\n",
    "By using these libraries, you can leverage the capabilities of TensorFlow to create and train recommendation models using the provided datasets and algorithms from tensorflow_recommenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e41774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf70dd",
   "metadata": {},
   "source": [
    "Loading the ratings data:\n",
    "\n",
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\"): This line loads the ratings data from the MovieLens 100K dataset using the TensorFlow Datasets (tfds) library. The split parameter is set to \"train,\" which indicates that you are loading the training split of the dataset.\n",
    "\n",
    "\n",
    "Loading the movie data:\n",
    "\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\"): This line loads the movie data from the MovieLens 100K dataset using TensorFlow Datasets. The split parameter is again set to \"train.\"\n",
    "\n",
    "This code snippet uses the map() function to transform the ratings data. It selects the \"movie_title\" and \"user_id\" features from each rating record, and the resulting dataset will contain only these two features.\n",
    "\n",
    "This code snippet uses the map() function to extract the \"movie_title\" feature from each movie record. The resulting dataset will only contain the movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae1aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\stilinski\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca5bdff70f747f4b4ba55ee779a6668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e3c8fc9c8847158409b40f2cf4967a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafc1166d22b4a43a8ec00a3eca2fbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\stilinski\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incompleteNWDA9W\\movielens-train…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset movielens downloaded and prepared to C:\\Users\\stilinski\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\stilinski\\tensorflow_datasets\\movielens\\100k-movies\\0.1.1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8292011a0984879bf9153ca5db2c72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5606e7324c4bc99c8eb510e7f467cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348abe7da5ff42b48a9b300a0cec86da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\stilinski\\tensorflow_datasets\\movielens\\100k-movies\\0.1.1.incompleteK0WLGG\\movielens-train.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset movielens downloaded and prepared to C:\\Users\\stilinski\\tensorflow_datasets\\movielens\\100k-movies\\0.1.1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"]\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a562595",
   "metadata": {},
   "source": [
    "we are creating vocabulary look-up tables for the user IDs and movie titles using tf.keras.layers.StringLookup. These look-up tables are used to map string values to integer indices, which can be useful for embedding or encoding categorical features in machine learning models.\n",
    "\n",
    "\n",
    "The movie_titles_vocabulary is created as a StringLookup layer instance with mask_token=None. The adapt() method is then called on this layer, passing the movies dataset. This process allows the vocabulary to be adapted based on the unique movie titles present in the dataset.\n",
    "\n",
    "The StringLookup layer analyzes the movie titles in the dataset and builds the vocabulary by mapping the unique titles to integer indices. The adapt() method is responsible for this adaptation process.\n",
    "\n",
    "By adapting the vocabulary look-up tables using the respective datasets, the StringLookup layers learn the mapping between the string values (user IDs and movie titles) and their corresponding integer indices. This mapping can be used later for feature encoding or embedding when building recommendation models.\n",
    "\n",
    "By adapting the vocabulary look-up tables using the respective datasets, the look-up tables learn the mapping between the string values (user IDs and movie titles) and integer indices. This mapping can be used later for feature encoding or embedding when building recommendation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2f25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
    "\n",
    "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4b5b7",
   "metadata": {},
   "source": [
    "__init__(self, user_model, movie_model, task): This is the constructor method of the MovieLensModel class. It takes three arguments:\n",
    "\n",
    "user_model: An instance of tf.keras.Model representing the user model. This model is responsible for learning user embeddings or representations.\n",
    "movie_model: An instance of tf.keras.Model representing the movie model. This model is responsible for learning movie embeddings or representations.\n",
    "task: An instance of tfrs.tasks.Retrieval representing the retrieval task. This task defines how the user and movie embeddings are compared or matched to compute the loss.\n",
    "compute_loss(self, features, training=False): This method computes the loss for the model. It takes the following arguments:\n",
    "\n",
    "features: A dictionary containing input features. In this case, it expects the \"user_id\" and \"movie_title\" features as keys, mapped to their respective tensor values.\n",
    "training: A boolean indicating whether the model is being trained or not (default is False).\n",
    "Inside the method, the user and movie embeddings are computed using the user and movie models, respectively. Then, the compute_loss method of the task object is called, passing the user embeddings and movie embeddings. The task's compute_loss method calculates the loss based on the defined retrieval task (e.g., pairwise ranking loss, pointwise loss, etc.), which is specific to the recommendation scenario.\n",
    "\n",
    "By implementing the MovieLensModel class, you define the structure and behavior of the recommendation model using user and movie models, as well as a specific retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babe0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      movie_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.movie_model = movie_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeddcb67",
   "metadata": {},
   "source": [
    "Here, the user_model is defined as a sequential model using tf.keras.Sequential. It consists of two layers:\n",
    "\n",
    "The first layer is user_ids_vocabulary, which is the vocabulary look-up table for user IDs that you created earlier. It maps the string user IDs to integer indices.\n",
    "The second layer is an Embedding layer with a vocabulary size equal to user_ids_vocabulary.vocab_size() and an embedding dimension of 64. This layer learns the user embeddings based on the integer indices obtained from the vocabulary look-up table.\n",
    "\n",
    "Similarly, the movie_model is defined as a sequential model. It also consists of two layers:\n",
    "\n",
    "The first layer is movie_titles_vocabulary, the vocabulary look-up table for movie titles created earlier. It maps the string movie titles to integer indices.\n",
    "The second layer is an Embedding layer with a vocabulary size equal to movie_titles_vocabulary.vocab_size() and an embedding dimension of 64. This layer learns the movie embeddings based on the integer indices obtained from the vocabulary look-up table.\n",
    "\n",
    "The retrieval task, tfrs.tasks.Retrieval, is defined with a specified metric, tfrs.metrics.FactorizedTopK. The FactorizedTopK metric is used to evaluate the performance of the model by measuring the top-K recommendations. In this case, movies.batch(128).map(movie_model) is passed as an argument to the metric. This indicates that the metric will be computed based on the movie embeddings obtained from the movie_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eef4acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "movie_model = tf.keras.Sequential([\n",
    "    movie_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    movies.batch(128).map(movie_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e309848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fae352b",
   "metadata": {},
   "source": [
    "Here, a retrieval model is created by instantiating the MovieLensModel class that you defined earlier. The user_model, movie_model, and task objects are passed as arguments to the constructor.\n",
    "The retrieval model is compiled by specifying an optimizer for training. In this case, the Adagrad optimizer with a learning rate of 0.5 is used.\n",
    "The retrieval model is trained using the fit() method. The ratings dataset is batched into batches of size 4096, and the model is trained for 10 epochs.\n",
    "A brute-force search index is created using tfrs.layers.factorized_top_k.BruteForce, which takes the user_model as an argument. Then, the index is built using the movie embeddings obtained from the movie_model and the movie titles from the movies dataset.\n",
    "Recommendations are obtained for a specific user (in this case, user ID \"30\") by querying the index with the user ID. The top recommendations are retrieved and printed.\n",
    "\n",
    "By creating the retrieval model, training it, setting up the retrieval index, and obtaining recommendations, you have completed the recommendation workflow using the MovieLens dataset and the defined model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0c9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 35s 1s/step - factorized_top_k/top_1_categorical_accuracy: 2.9000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0101 - factorized_top_k/top_50_categorical_accuracy: 0.0742 - factorized_top_k/top_100_categorical_accuracy: 0.1563 - loss: 33185.2468 - regularization_loss: 0.0000e+00 - total_loss: 33185.2468\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 34s 1s/step - factorized_top_k/top_1_categorical_accuracy: 5.2000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0077 - factorized_top_k/top_10_categorical_accuracy: 0.0201 - factorized_top_k/top_50_categorical_accuracy: 0.1348 - factorized_top_k/top_100_categorical_accuracy: 0.2559 - loss: 30589.0644 - regularization_loss: 0.0000e+00 - total_loss: 30589.0644\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 33s 1s/step - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0101 - factorized_top_k/top_10_categorical_accuracy: 0.0266 - factorized_top_k/top_50_categorical_accuracy: 0.1717 - factorized_top_k/top_100_categorical_accuracy: 0.3087 - loss: 30138.1965 - regularization_loss: 0.0000e+00 - total_loss: 30138.1965\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 40s 2s/step - factorized_top_k/top_1_categorical_accuracy: 4.7000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0107 - factorized_top_k/top_10_categorical_accuracy: 0.0302 - factorized_top_k/top_50_categorical_accuracy: 0.1931 - factorized_top_k/top_100_categorical_accuracy: 0.3395 - loss: 29857.8512 - regularization_loss: 0.0000e+00 - total_loss: 29857.8512\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 30s 1s/step - factorized_top_k/top_1_categorical_accuracy: 4.2000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0113 - factorized_top_k/top_10_categorical_accuracy: 0.0317 - factorized_top_k/top_50_categorical_accuracy: 0.2110 - factorized_top_k/top_100_categorical_accuracy: 0.3656 - loss: 29646.4737 - regularization_loss: 0.0000e+00 - total_loss: 29646.4737\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 33s 1s/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0117 - factorized_top_k/top_10_categorical_accuracy: 0.0335 - factorized_top_k/top_50_categorical_accuracy: 0.2245 - factorized_top_k/top_100_categorical_accuracy: 0.3832 - loss: 29474.5463 - regularization_loss: 0.0000e+00 - total_loss: 29474.5463\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 34s 1s/step - factorized_top_k/top_1_categorical_accuracy: 4.4000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0122 - factorized_top_k/top_10_categorical_accuracy: 0.0342 - factorized_top_k/top_50_categorical_accuracy: 0.2352 - factorized_top_k/top_100_categorical_accuracy: 0.3983 - loss: 29334.9391 - regularization_loss: 0.0000e+00 - total_loss: 29334.9391\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 31s 1s/step - factorized_top_k/top_1_categorical_accuracy: 4.3000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0126 - factorized_top_k/top_10_categorical_accuracy: 0.0351 - factorized_top_k/top_50_categorical_accuracy: 0.2438 - factorized_top_k/top_100_categorical_accuracy: 0.4105 - loss: 29214.4182 - regularization_loss: 0.0000e+00 - total_loss: 29214.4182\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 31s 1s/step - factorized_top_k/top_1_categorical_accuracy: 4.3000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0127 - factorized_top_k/top_10_categorical_accuracy: 0.0355 - factorized_top_k/top_50_categorical_accuracy: 0.2509 - factorized_top_k/top_100_categorical_accuracy: 0.4213 - loss: 29113.4268 - regularization_loss: 0.0000e+00 - total_loss: 29113.4268\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 31s 1s/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0132 - factorized_top_k/top_10_categorical_accuracy: 0.0367 - factorized_top_k/top_50_categorical_accuracy: 0.2577 - factorized_top_k/top_100_categorical_accuracy: 0.4309 - loss: 29023.8773 - regularization_loss: 0.0000e+00 - total_loss: 29023.8773\n",
      "Top 3 recommendations for user 30: [b'Flubber (1997)' b'Mouse Hunt (1997)' b'Rocket Man (1997)']\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(user_model, movie_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ratings.batch(4096), epochs=10)\n",
    "\n",
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n",
    "\n",
    "# Get some recommendations.\n",
    "_, titles = index(np.array([\"30\"]))\n",
    "print(f\"Top 3 recommendations for user 30: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878e563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd918aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eee901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ad2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13feb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f59e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea294fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514e126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2432b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84627ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943f725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786692d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee848c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f5189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
